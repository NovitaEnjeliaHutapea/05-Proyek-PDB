{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA7AS6Y676HI"
      },
      "source": [
        "## Kelompok 5\n",
        " \n",
        "### 12S18002 - Wiranda Siahaan\n",
        "### 12S18009 - Novita Hutapea\n",
        "### 12S18041 - Merika Manurung\n",
        "### 12S18046 - Tiara Situmorang"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44lXVCi3zytQ"
      },
      "source": [
        "**Consume twitter steaming data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZWW5_0lTq40"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNTQdnW1y17N"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "import socket\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I4puMqI0A-d"
      },
      "source": [
        "Insert your credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFEpyHfq0Acj"
      },
      "outputs": [],
      "source": [
        "#Kindly put your credentials received from twitter developer account\n",
        "consumer_key='2mTmxHwkZramjVDOewE2dybgQ'\n",
        "consumer_secret='dJ42E93prTAze5BoF4wAIcxYA6gXfu9rGrHr6gguUt85xcHJSi'\n",
        "access_token ='1517128047019040768-YMZCcFIf6VLbZXNkJsa79sZk70xFkM'\n",
        "access_secret='Auwa9WPIktjUCrgQmzceZsdMtMA2hbnebSR7QlmYEdrlq'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU17R4C3T2XZ"
      },
      "outputs": [],
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "api = tweepy.API(auth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZFGsBd0T4er"
      },
      "outputs": [],
      "source": [
        "for tweet in api.search(q='miniso', lan='en'):    \n",
        "    print(tweet.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1iYhAwqT6Ce"
      },
      "outputs": [],
      "source": [
        "tweetDf = pd.DataFrame(columns = ['User', 'User_statuses_count', \n",
        "                             'user_followers','fav_count','User_location','Tweets',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuV9jcqaT-dI"
      },
      "outputs": [],
      "source": [
        "def stream(data, file_name):\n",
        "    i = 0\n",
        "    for tweet in tweepy.Cursor(api.search, q=data, count=100000, lang='en').items():\n",
        "        print(i, end='\\r')\n",
        "        tweetDf.loc[i, 'User'] = tweet.user.name\n",
        "        tweetDf.loc[i, 'User_statuses_count'] = tweet.user.statuses_count\n",
        "        tweetDf.loc[i, 'user_followers'] = tweet.user.followers_count\n",
        "        tweetDf.loc[i, 'fav_count'] = tweet.favorite_count\n",
        "        tweetDf.loc[i, 'User_location'] = tweet.user.location\n",
        "        tweetDf.loc[i, 'Tweets'] = tweet.text\n",
        "        \n",
        "        \n",
        "        tweetDf.to_csv('{}.csv'.format(file_name))\n",
        "        i+=1\n",
        "        if i == 200:\n",
        "            break\n",
        "        else:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAVB2u1MUBAJ"
      },
      "outputs": [],
      "source": [
        "stream(data = ['miniso'], file_name = 'miniso_2021')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9_bmsJDUCTo"
      },
      "outputs": [],
      "source": [
        "tweetDf.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# libraries\n",
        "import numpy as np # used for handling numbers\n",
        "import pandas as pd # used for handling the dataset\n",
        "from sklearn.impute import SimpleImputer # used for handling missing data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
        "from sklearn.model_selection import train_test_split # used for splitting training and testing data\n",
        "from sklearn.preprocessing import StandardScaler # used for feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('miniso_2021.csv') # to import the dataset into a variable\n",
        "# Splitting the attributes into independent and dependent attributes\n",
        "X = dataset.iloc[:, :-1].values # attributes to determine dependent variable / Class\n",
        "Y = dataset.iloc[:, -1].values # dependent variable / Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# handling the missing data and replace missing values with nan from numpy and replace with mean of all the other values\n",
        "dataset1 = dataset.dropna()\n",
        "print(dataset1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### remove duplicate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset2 = dataset1.drop_duplicates()\n",
        "print(dataset2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Twitter_Sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
